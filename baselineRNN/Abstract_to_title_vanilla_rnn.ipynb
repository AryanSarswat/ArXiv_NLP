{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxiBjiN7caiJ"
      },
      "source": [
        "Abstract to title NLP model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8VfrUcHqKAa"
      },
      "source": [
        "## 1. Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvvU1FzFsz3f"
      },
      "outputs": [],
      "source": [
        "!gdown 1qYdSlDJ89AvgozK3V5tik8Op93zPbG6e -O processed_CMDC.pkl\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/datasetNLP') #change this to the directory where the data is\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "Qc4OlbdYEKBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "TIkNu1zhLAtR"
      },
      "outputs": [],
      "source": [
        "# ===========================================================================\n",
        "# Run some setup code for this notebook. Don't modify anything in this cell.\n",
        "# ===========================================================================\n",
        "\n",
        "import csv, random, re, os, math, pickle, statistics, tqdm, numpy as np\n",
        "from io import open\n",
        "from google.colab import files\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.jit import trace\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# ===========================================================================\n",
        "# A quick note on CUDA functionality (and `.to(model.device)`):\n",
        "# CUDA is a parallel GPU platform produced by NVIDIA and is used by most GPU\n",
        "# libraries in PyTorch. CUDA organizes GPUs into device IDs (i.e., \"cuda:X\" for GPU #X).\n",
        "# \"device\" will tell PyTorch which GPU (or CPU) to place an object in. Since\n",
        "# collab only uses one GPU, we will use 'cuda' as the device if a GPU is available\n",
        "# and the CPU if not. You will run into problems if your tensors are on different devices.\n",
        "# ===========================================================================\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0QVuKL9sfqS"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA4RhP1Rfegu"
      },
      "source": [
        "### 1.1 Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "rTlgiBNWPrVQ"
      },
      "outputs": [],
      "source": [
        "def print_list(l, K=None):\n",
        "\tfor i, e in enumerate(l):\n",
        "\t\tif i == K:\n",
        "\t\t\tbreak\n",
        "\t\tprint(e)\n",
        "\tprint()\n",
        "\n",
        "def load_from_pickle(pickle_file):\n",
        "\twith open(pickle_file, \"rb\") as pickle_in:\n",
        "\t\treturn pickle.load(pickle_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l4KOwIsNWqb"
      },
      "outputs": [],
      "source": [
        "cols = ['id', 'title', 'abstract', 'categories']\n",
        "data = []\n",
        "file_name = './arxiv-metadata-oai-snapshot.json'\n",
        "\n",
        "# Open the file and read data\n",
        "with open(file_name, encoding='latin-1') as f:\n",
        "    count = 0\n",
        "    for line in f:\n",
        "        doc = json.loads(line)\n",
        "        lst = [doc['id'], doc['title'], doc['abstract'], doc['categories']]\n",
        "        data.append(lst)\n",
        "        count += 1\n",
        "        # Read 11,000 entries\n",
        "        if count >= 11000:\n",
        "            break\n",
        "\n",
        "# Create a DataFrame from the data list\n",
        "df = pd.DataFrame(data=data, columns=cols)\n",
        "# df = df.sample(frac=1, random_state=68).reset_index(drop=True)\n",
        "\n",
        "\n",
        "train_df = df.iloc[:10000]  #\n",
        "test_df = df.iloc[10000:]\n",
        "\n",
        "\n",
        "print(\"Training DataFrame:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nTesting DataFrame:\")\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zfGojqcqmLK"
      },
      "outputs": [],
      "source": [
        "\n",
        "pad_word = \"<pad>\"\n",
        "bos_word = \"<s>\"\n",
        "eos_word = \"</s>\"\n",
        "unk_word = \"<unk>\"\n",
        "pad_id = 0\n",
        "bos_id = 1\n",
        "eos_id = 2\n",
        "unk_id = 3\n",
        "\n",
        "def normalize_sentence(s):\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.word_to_id = {pad_word: pad_id, bos_word: bos_id, eos_word:eos_id, unk_word: unk_id}\n",
        "        self.word_count = {}\n",
        "        self.id_to_word = {pad_id: pad_word, bos_id: bos_word, eos_id: eos_word, unk_id: unk_word}\n",
        "        self.num_words = 4\n",
        "\n",
        "    def get_ids_from_sentence(self, sentence):\n",
        "        sentence = normalize_sentence(sentence)\n",
        "        sent_ids = [bos_id] + [self.word_to_id[word] if word in self.word_to_id \\\n",
        "                               else unk_id for word in sentence.split()] + \\\n",
        "                               [eos_id]\n",
        "        return sent_ids\n",
        "\n",
        "    def tokenized_sentence(self, sentence):\n",
        "        sent_ids = self.get_ids_from_sentence(sentence)\n",
        "        return [self.id_to_word[word_id] for word_id in sent_ids]\n",
        "\n",
        "    def decode_sentence_from_ids(self, sent_ids):\n",
        "        words = list()\n",
        "        for i, word_id in enumerate(sent_ids):\n",
        "            if word_id in [bos_id, eos_id, pad_id]:\n",
        "                # Skip these words\n",
        "                continue\n",
        "            else:\n",
        "                words.append(self.id_to_word[word_id])\n",
        "        return ' '.join(words)\n",
        "\n",
        "    def add_words_from_sentence(self, sentence):\n",
        "        sentence = normalize_sentence(sentence)\n",
        "        for word in sentence.split():\n",
        "            if word not in self.word_to_id:\n",
        "                # add this word to the vocabulary\n",
        "                self.word_to_id[word] = self.num_words\n",
        "                self.id_to_word[self.num_words] = word\n",
        "                self.word_count[word] = 1\n",
        "                self.num_words += 1\n",
        "            else:\n",
        "                # update the word count\n",
        "                self.word_count[word] += 1\n",
        "abstracts_only = []\n",
        "titles_only = []\n",
        "vocab = Vocabulary()\n",
        "for ids, title, abstract, categories in data:\n",
        "    abstracts_only.append(abstract)\n",
        "    titles_only.append(title)\n",
        "for index, row in train_df.iterrows():\n",
        "    vocab.add_words_from_sentence(row['abstract'])\n",
        "    vocab.add_words_from_sentence(row[\"title\"])\n",
        "print(f\"Total words in the vocabulary = {vocab.num_words}\")\n",
        "print(len(titles_only))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIZG1fmA1BED"
      },
      "outputs": [],
      "source": [
        "for ids, title, abstract, categories in data[:2]:\n",
        "    sentence = abstract\n",
        "    word_tokens = vocab.tokenized_sentence(sentence)\n",
        "\n",
        "    # Automatically adds bos_id and eos_id before and after sentence ids respectively\n",
        "    word_ids = vocab.get_ids_from_sentence(sentence)\n",
        "    print(sentence)\n",
        "    print(word_tokens)\n",
        "    print(word_ids)\n",
        "    print(vocab.decode_sentence_from_ids(word_ids))\n",
        "    print()\n",
        "\n",
        "word = \"the\"\n",
        "word_id = vocab.word_to_id[word]\n",
        "print(f\"Word = {word}\")\n",
        "print(f\"Word ID = {word_id}\")\n",
        "print(f\"Word decoded from ID = {vocab.decode_sentence_from_ids([word_id])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVbxmW8N3qL4"
      },
      "source": [
        "### 1.3 Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "92DIBSL43pJT"
      },
      "outputs": [],
      "source": [
        "class ABS_Title_Data(Dataset):\n",
        "    \"\"\"Single-Turn version of Cornell Movie Dialog Cropus dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, abstracts,titles,  vocab, device):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            conversations: list of tuple (src_string, tgt_string)\n",
        "                         - src_string: String of the source sentence\n",
        "                         - tgt_string: String of the target sentence\n",
        "            vocab: Vocabulary object that contains the mapping of\n",
        "                    words to indices\n",
        "            device: cpu or cuda\n",
        "        \"\"\"\n",
        "        self.abstract_title = list(zip(abstracts, titles))\n",
        "        self.vocab = vocab\n",
        "        self.device = device\n",
        "\n",
        "        def encode(src, tgt):\n",
        "            src_ids = self.vocab.get_ids_from_sentence(src)\n",
        "            tgt_ids = self.vocab.get_ids_from_sentence(tgt)\n",
        "            return (src_ids, tgt_ids)\n",
        "\n",
        "        # We will pre-tokenize the conversations and save in id lists for later use\n",
        "        self.tokenized_conversations = [encode(src, tgt) for src, tgt in self.abstract_title]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.abstract_title)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        return {\"conv_ids\":self.tokenized_conversations[idx], \"conv\":self.abstract_title[idx]}\n",
        "\n",
        "def collate_fn(data):\n",
        "\n",
        "    # Sort conv_ids based on decreasing order of the src_lengths.\n",
        "    # This is required for efficient GPU computations.\n",
        "    src_ids = [torch.LongTensor(e[\"conv_ids\"][0]) for e in data]\n",
        "    tgt_ids = [torch.LongTensor(e[\"conv_ids\"][1]) for e in data]\n",
        "    src_str = [e[\"conv\"][0] for e in data]\n",
        "    tgt_str = [e[\"conv\"][1] for e in data]\n",
        "    data = list(zip(src_ids, tgt_ids, src_str, tgt_str))\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    src_ids, tgt_ids, src_str, tgt_str = zip(*data)\n",
        "\n",
        "    ### BEGIN YOUR CODE ###\n",
        "\n",
        "    # Pad the src_ids and tgt_ids using token pad_id to create src_seqs and tgt_seqs\n",
        "    src_seqs = nn.utils.rnn.pad_sequence(src_ids, padding_value=0)\n",
        "\n",
        "    tgt_seqs = nn.utils.rnn.pad_sequence(tgt_ids, padding_value=0)\n",
        "\n",
        "    ### END YOUR CODE ###\n",
        "\n",
        "    return {\"conv_ids\":(src_ids, tgt_ids), \"conv\":(src_str, tgt_str), \"conv_tensors\":(src_seqs.to(device), tgt_seqs.to(device))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "lAQ26bgF4GT1"
      },
      "outputs": [],
      "source": [
        "# Create the DataLoader for all_conversations\n",
        "dataset = ABS_Title_Data(abstracts_only, titles_only, vocab, device)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8vYxSJl4NNp"
      },
      "outputs": [],
      "source": [
        "# Test one batch of training data\n",
        "first_batch = next(iter(data_loader))\n",
        "print(f\"Testing first training batch of size {len(first_batch['conv'][0])}\")\n",
        "print(f\"List of source strings:\")\n",
        "print_list(first_batch[\"conv\"][0])\n",
        "print(f\"Tokenized source ids:\")\n",
        "print_list(first_batch[\"conv_ids\"][0])\n",
        "print(f\"Padded source ids as tensor (shape {first_batch['conv_tensors'][0].size()}):\")\n",
        "print(first_batch[\"conv_tensors\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "s4QitXM9Szr9"
      },
      "outputs": [],
      "source": [
        "class Seq2seqBaseline(nn.Module):\n",
        "    def __init__(self, vocab, emb_dim=300, hidden_dim=300, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_words = num_words = vocab.num_words\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(num_embeddings=num_words, embedding_dim=emb_dim)\n",
        "\n",
        "        # Encoder with Bidirectional RNN\n",
        "        self.erNN = nn.RNN(input_size=emb_dim, hidden_size=hidden_dim, num_layers=num_layers,\n",
        "                           dropout=dropout, bidirectional=True)\n",
        "\n",
        "        # Decoder RNN uses doubled hidden size from bidirectional encoder\n",
        "        DH = hidden_dim * 2  # Adjusted hidden dimension for decoder\n",
        "        self.drNN = nn.RNN(input_size=emb_dim, hidden_size=DH, num_layers=num_layers,\n",
        "                           dropout=dropout, bidirectional=False)\n",
        "\n",
        "        # Output layer remains the same\n",
        "        self.linear = nn.Linear(DH, num_words)\n",
        "\n",
        "    def encode(self, source, pad_id):\n",
        "        source_lengths = torch.sum((source != pad_id).int(), dim=0).cpu()\n",
        "        mask = (source != pad_id)\n",
        "        w2i = self.embedding(source)\n",
        "        packedbatch = nn.utils.rnn.pack_padded_sequence(w2i, source_lengths.cpu())\n",
        "        packedO, hidden = self.erNN(packedbatch)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packedO, batch_first=True)\n",
        "        outputs = outputs[:, :, :self.hidden_dim] + outputs[:, :, self.hidden_dim:]\n",
        "        hidden = hidden.view(self.num_layers, 2, -1, self.hidden_dim)\n",
        "        hidden = torch.cat((hidden[:, 0, :, :], hidden[:, 1, :, :]), dim=2)\n",
        "        return outputs, mask, hidden\n",
        "\n",
        "    def decode(self, decoder_input, last_hidden):\n",
        "        output, hidden = None, None\n",
        "        embed = self.embedding(decoder_input)\n",
        "        gOut, hidden = self.drNN(embed, last_hidden)\n",
        "        output = self.linear(gOut.squeeze(0))\n",
        "        return output, hidden\n",
        "\n",
        "    def compute_loss(self, source, target):\n",
        "        loss = 0\n",
        "        nonPadTok = 0\n",
        "        loss_fn = nn.CrossEntropyLoss(ignore_index=pad_id, reduction='none')\n",
        "        eout, emask, ehidden = self.encode(source, pad_id)\n",
        "        din = torch.full((1, source.size(1)), bos_id, device=source.device)\n",
        "        dhidden = ehidden\n",
        "        for i in range(target.size(0)):\n",
        "            dout, dhidden = self.decode(din, dhidden)\n",
        "            currLoss = loss_fn(dout, target[i])\n",
        "            m = target[i] != pad_id\n",
        "            loss += currLoss[m].sum()\n",
        "            nonPadTok += m.sum()\n",
        "            din = target[i].unsqueeze(0)\n",
        "        loss = loss / nonPadTok\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "rrFiSD1sZCUN"
      },
      "outputs": [],
      "source": [
        "def train(model, data_loader, num_epochs, model_file, learning_rate=0.0001):\n",
        "    decoder_learning_ratio = 5.0\n",
        "    encoder_parameter_names = ['embedding', 'egru']\n",
        "    encoder_named_params = list(filter(lambda kv: any(key in kv[0] for key in encoder_parameter_names), model.named_parameters()))\n",
        "    decoder_named_params = list(filter(lambda kv: not any(key in kv[0] for key in encoder_parameter_names), model.named_parameters()))\n",
        "    encoder_params = [e[1] for e in encoder_named_params]\n",
        "    decoder_params = [e[1] for e in decoder_named_params]\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': encoder_params},\n",
        "        {\n",
        "            'params': decoder_params,\n",
        "            'lr': learning_rate * decoder_learning_ratio\n",
        "        }\n",
        "    ], lr = learning_rate)\n",
        "\n",
        "    clip = 50.0\n",
        "    for epoch in tqdm.trange(num_epochs, desc=\"training\", unit=\"epoch\"):\n",
        "        with tqdm.tqdm(data_loader, desc=f\"epoch {epoch + 1}\", unit=\"batch\", total=len(data_loader), position=0, leave=True) as batch_iterator:\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for i, batch_data in enumerate(batch_iterator, start=1):\n",
        "                source, target = batch_data[\"conv_tensors\"]\n",
        "                optimizer.zero_grad()\n",
        "                loss = model.compute_loss(source, target)\n",
        "                total_loss += loss.item()\n",
        "                loss.backward()\n",
        "                _ = nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "                optimizer.step()\n",
        "\n",
        "                batch_iterator.set_postfix(mean_loss=total_loss / i, current_loss=loss.item())\n",
        "    torch.save(model.state_dict(), model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVqQnn59ZuHj"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "baseline_model = Seq2seqBaseline(vocab).to(device)\n",
        "train(baseline_model, data_loader, num_epochs, \"baseline_model.pt\")\n",
        "files.download('baseline_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U83z2yBBw8_N"
      },
      "outputs": [],
      "source": [
        "baseline_model = Seq2seqBaseline(vocab).to(device)\n",
        "baseline_model.load_state_dict(torch.load(\"baseline_model.pt\", map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(baseline_model)"
      ],
      "metadata": {
        "id": "Lr8dfrZw3NyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "HG-_G8wZdlJh"
      },
      "outputs": [],
      "source": [
        "def predict_greedy(model, sentence, max_length=100):\n",
        "    model.eval()\n",
        "    generation = None\n",
        "    generation = vocab.get_ids_from_sentence(sentence)\n",
        "    sentence_ids = vocab.get_ids_from_sentence(sentence)\n",
        "    sentence_tensor = torch.tensor(sentence_ids, dtype=torch.long).unsqueeze(1)\n",
        "    sentence_tensor = sentence_tensor.to(device)\n",
        "    with torch.no_grad():\n",
        "      eout, emask, ehidden = model.encode(sentence_tensor, pad_id)\n",
        "      tensorInput = [bos_id]\n",
        "      din = torch.tensor(tensorInput,device= device)\n",
        "      dhidden = ehidden\n",
        "      dwords = []\n",
        "      for i in range(max_length):\n",
        "        din = din.unsqueeze(1)\n",
        "        dout, dhidden = model.decode(din, dhidden)\n",
        "        topValues, topi = dout.topk(1)\n",
        "        if topi.item() == eos_id:\n",
        "          break\n",
        "        else:\n",
        "          dwords.append(topi.item())\n",
        "        din = topi.squeeze().detach()\n",
        "        din = din.unsqueeze(0)\n",
        "\n",
        "      generation = ' '.join([vocab.id_to_word[index] for index in dwords])\n",
        "      generation = vocab.decode_sentence_from_ids(dwords)\n",
        "    return generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33nlueyWvUM4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)\n",
        "first_five_pairs = dataset.abstract_title[10000:10100]\n",
        "rouge_scores = []\n",
        "bleu_scores = []\n",
        "total_rouge1 = total_rouge2 = total_rougeL = total_rougeLsum = 0\n",
        "total_bleu = 0\n",
        "for abstract, reference_title in first_five_pairs:\n",
        "    generated_title = predict_greedy(baseline_model, abstract, max_length=100)\n",
        "    rouge_score = scorer.score(reference_title, generated_title)\n",
        "    rouge_scores.append(rouge_score)\n",
        "    total_rouge1 += rouge_score['rouge1'].fmeasure\n",
        "    total_rouge2 += rouge_score['rouge2'].fmeasure\n",
        "    total_rougeL += rouge_score['rougeL'].fmeasure\n",
        "    total_rougeLsum += rouge_score['rougeLsum'].fmeasure\n",
        "    bleu_score = sentence_bleu([reference_title.split()], generated_title.split(), smoothing_function=SmoothingFunction().method1)\n",
        "    bleu_scores.append(bleu_score)\n",
        "    total_bleu += bleu_score\n",
        "average_rouge1 = total_rouge1 / len(first_five_pairs)\n",
        "average_rouge2 = total_rouge2 / len(first_five_pairs)\n",
        "average_rougeL = total_rougeL / len(first_five_pairs)\n",
        "average_rougeLsum = total_rougeLsum / len(first_five_pairs)\n",
        "average_bleu = total_bleu / len(first_five_pairs)\n",
        "print(\"Average ROUGE-1 Score:\", average_rouge1)\n",
        "print(\"Average ROUGE-2 Score:\", average_rouge2)\n",
        "print(\"Average ROUGE-L Score:\", average_rougeL)\n",
        "print(\"Average ROUGE-Lsum Score:\", average_rougeLsum)\n",
        "print(\"Average BLEU Score:\", average_bleu)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}